{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Tensorflow (Bonus)\n",
    "**Description:** Prepare a Neural Network Model for the case above using Tensorflow. You can write your own code [bonus] or use snippets from any solutions found online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Layer, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Preceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear class for mlp\n",
    "class Linear(Layer):\n",
    "  def __init__(self, units=2, **kwargs):\n",
    "    super(Linear, self).__init__(**kwargs)\n",
    "    self.units = units \n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.w = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "    self.b = self.add_weight(\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "  def call(self, inputs):\n",
    "    return tf.matmul(inputs, self.w) + self.b\n",
    "\n",
    "  def get_config(self): \n",
    "    config = super(Linear, self).get_config()\n",
    "    config.update({'units': self.units})\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mlp class to develop neural network\n",
    "class MLP(Layer):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear_1 = Linear(3)\n",
    "        self.linear_2 = Linear(2)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.linear_1(inputs)\n",
    "        x = tf.nn.tanh(x)\n",
    "        x = self.linear_2(x)\n",
    "        x = tf.nn.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "    def build_graph(self, raw_shape):\n",
    "        x = Input(shape=raw_shape)\n",
    "        return Model(inputs=[x], outputs=self.call(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(step, x, y):\n",
    "    ''' input: x, y <- typically batches \n",
    "        input: step <- batch step\n",
    "        return: loss values'''\n",
    "   \n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = mlp(x, training=True) # forward pass\n",
    "        train_loss_value = loss_fn(y, logits) # loss function\n",
    "\n",
    "    # compute gradient for backpropagation\n",
    "    grads = tape.gradient(train_loss_value, mlp.trainable_weights)\n",
    "\n",
    "    # update weights\n",
    "    optimizer.apply_gradients(zip(grads, mlp.trainable_weights))\n",
    "\n",
    "    # update metric\n",
    "    train_acc_metric.update_state(y, logits)\n",
    "\n",
    "    return train_loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(step, x, y):\n",
    "    ''' input: x, y <- typically batches \n",
    "    input: step <- batch step\n",
    "    return: loss value '''\n",
    "\n",
    "    # forward pass, no backpropagation\n",
    "    val_logits = mlp(x, training=False) \n",
    "\n",
    "    # Compute the loss value \n",
    "    val_loss_value = loss_fn(y, val_logits)\n",
    "\n",
    "    # Update val metric\n",
    "    val_acc_metric.update_state(y, val_logits)\n",
    "\n",
    "\n",
    "    return val_loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy data\n",
    "np.random.seed(1)\n",
    "x_train = np.random.randint(10,size=(10,2))*np.ones([10,2])\n",
    "y_train = np.random.randint(10,size=(10,2))*np.ones([10,2])\n",
    "\n",
    "x_test = np.random.randint(10,size=(5,2))*np.ones([5,2])\n",
    "y_test = np.random.randint(10,size=(5,2))*np.ones([5,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-16 16:19:49.517009: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Prepare the training dataset.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)\n",
    "\n",
    "# Prepare the validation dataset.\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "val_dataset = val_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP() # initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial parameters\n",
    "optimizer = tf.keras.optimizers.SGD() # Stochastic Gradient Descent\n",
    "\n",
    "# initiate performance metrics\n",
    "loss_fn = tf.keras.losses.MeanSquaredError() \n",
    "train_acc_metric = tf.keras.metrics.Accuracy()\n",
    "val_acc_metric   = tf.keras.metrics.Accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 34.4508056640625  acc: 0.0 validation_loss: 37.41999816894531 val acc: 0.0\n",
      "\n",
      "epoch: 2 loss: 34.405364990234375  acc: 0.0 validation_loss: 37.37744903564453 val acc: 0.0\n",
      "\n",
      "epoch: 3 loss: 34.35980224609375  acc: 0.0 validation_loss: 37.33461380004883 val acc: 0.0\n",
      "\n",
      "epoch: 4 loss: 34.31391143798828  acc: 0.0 validation_loss: 37.29127883911133 val acc: 0.0\n",
      "\n",
      "epoch: 5 loss: 34.26748275756836  acc: 0.0 validation_loss: 37.24724578857422 val acc: 0.0\n",
      "\n",
      "epoch: 6 loss: 34.22031784057617  acc: 0.0 validation_loss: 37.20232391357422 val acc: 0.0\n",
      "\n",
      "epoch: 7 loss: 34.1722412109375  acc: 0.0 validation_loss: 37.156349182128906 val acc: 0.0\n",
      "\n",
      "epoch: 8 loss: 34.123077392578125  acc: 0.0 validation_loss: 37.109169006347656 val acc: 0.0\n",
      "\n",
      "epoch: 9 loss: 34.072731018066406  acc: 0.0 validation_loss: 37.060691833496094 val acc: 0.0\n",
      "\n",
      "epoch: 10 loss: 34.021087646484375  acc: 0.0 validation_loss: 37.01082229614258 val acc: 0.0\n",
      "\n",
      "epoch: 11 loss: 33.968116760253906  acc: 0.0 validation_loss: 36.95951461791992 val acc: 0.0\n",
      "\n",
      "epoch: 12 loss: 33.91379928588867  acc: 0.0 validation_loss: 36.90675735473633 val acc: 0.0\n",
      "\n",
      "epoch: 13 loss: 33.858158111572266  acc: 0.0 validation_loss: 36.85255432128906 val acc: 0.0\n",
      "\n",
      "epoch: 14 loss: 33.801239013671875  acc: 0.0 validation_loss: 36.79693603515625 val acc: 0.0\n",
      "\n",
      "epoch: 15 loss: 33.74311447143555  acc: 0.0 validation_loss: 36.739967346191406 val acc: 0.0\n",
      "\n",
      "epoch: 16 loss: 33.68389129638672  acc: 0.0 validation_loss: 36.68172073364258 val acc: 0.0\n",
      "\n",
      "epoch: 17 loss: 33.623680114746094  acc: 0.0 validation_loss: 36.622291564941406 val acc: 0.0\n",
      "\n",
      "epoch: 18 loss: 33.5626220703125  acc: 0.0 validation_loss: 36.561798095703125 val acc: 0.0\n",
      "\n",
      "epoch: 19 loss: 33.50086212158203  acc: 0.0 validation_loss: 36.5003662109375 val acc: 0.0\n",
      "\n",
      "epoch: 20 loss: 33.438568115234375  acc: 0.0 validation_loss: 36.43812942504883 val acc: 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# training loop \n",
    "for epoch in range(20):\n",
    "    # Iterate over the batches of the train dataset.\n",
    "    for train_batch_step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
    "        train_batch_step = tf.convert_to_tensor(train_batch_step, dtype=tf.int64)\n",
    "        train_loss_value = train_step(train_batch_step, \n",
    "                                      x_batch_train, y_batch_train)\n",
    "\n",
    "    # evaluation on validation set \n",
    "    for test_batch_step, (x_batch_val, y_batch_val) in enumerate(val_dataset):\n",
    "        test_batch_step = tf.convert_to_tensor(test_batch_step, dtype=tf.int64)\n",
    "        val_loss_value = test_step(test_batch_step, x_batch_val, y_batch_val)\n",
    "\n",
    "\n",
    "    template = 'epoch: {} loss: {}  acc: {} validation_loss: {} val acc: {}\\n'\n",
    "    print(template.format(\n",
    "        epoch + 1,\n",
    "        train_loss_value, (train_acc_metric.result()),\n",
    "        val_loss_value, float(val_acc_metric.result())\n",
    "    ))\n",
    "        \n",
    "    # Reset metrics at the end of each epoch\n",
    "    train_acc_metric.reset_states()\n",
    "    val_acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0cb40e781e312362eff528fa845c02808a47435732ff3c7b4c29a9d033ecae7b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 ('envSpot': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
